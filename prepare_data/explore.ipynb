{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7382d41-7659-45ae-9149-bf60b404c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import imageio\n",
    "import mediapy\n",
    "import json\n",
    "import numpy as np\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ea722",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _point_overlap(a: np.ndarray, b: np.ndarray) -> int:\n",
    "    n, i, j = 0, 0, 0\n",
    "    while i < len(a) and j < len(b):\n",
    "        if a[i] == b[j]:\n",
    "            n += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif a[i] < b[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "    return n\n",
    "\n",
    "@dataclass\n",
    "class Image:\n",
    "    id: int\n",
    "    qvec: np.ndarray\n",
    "    tvec: np.ndarray\n",
    "    camera_id: int\n",
    "    name: str\n",
    "    n_features: int\n",
    "    point3D_ids: np.ndarray # sorted\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        ''' simplify repr by only providing id, name, number of features and number of point ids '''\n",
    "        return f\"Image(id={self.id}, name={self.name}, n_features={self.n_features}, n_point3D_ids={len(self.point3D_ids)})\"\n",
    "    \n",
    "    def point_overlap(self, other: Image) -> int:\n",
    "        return _point_overlap(self.point3D_ids, other.point3D_ids)\n",
    "\n",
    "def read_images_text(path):\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "\n",
    "                n_features = len(point3D_ids)\n",
    "                point3D_ids = point3D_ids[point3D_ids != -1]\n",
    "                point3D_ids = point3D_ids[np.argsort(point3D_ids)]\n",
    "\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id,\n",
    "                    qvec=qvec,\n",
    "                    tvec=tvec,\n",
    "                    camera_id=camera_id,\n",
    "                    name=image_name,\n",
    "                    n_features=n_features,\n",
    "                    point3D_ids=point3D_ids,\n",
    "                )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafbc16-4bd6-4ebb-9b9a-b9423b1ca87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/cvlabdata1/cvlab/datasets_tyszkiew/compacted-datasets/megadepth/dataset.json', 'r') as json_file:\n",
    "    dataset_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e82968",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = '0162'\n",
    "\n",
    "scene_dataset_dict = dataset_dict[scene_id]\n",
    "id_to_image_dataset = scene_dataset_dict['images']\n",
    "id_triples = scene_dataset_dict['tuples']\n",
    "json_pairs = []\n",
    "for t1, t2, t3 in id_triples:\n",
    "    json_pairs.extend([(id_to_image_dataset[t1], id_to_image_dataset[t2]), (id_to_image_dataset[t1], id_to_image_dataset[t3]), (id_to_image_dataset[t2], id_to_image_dataset[t3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de947981",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_in_sfm = read_images_text(f'/cvlabdata1/cvlab/datasets_tyszkiew/megadepth/MegaDepth_v1_SfM/{scene_id}/sparse/manhattan/0/images.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_id_colmap = {im.name: im.id for im in images_in_sfm.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0259707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def pair_to_images(pair: tuple[str, str]) -> tuple[Image, Image]:\n",
    "    return images_in_sfm[image_to_id_colmap[pair[0]]], images_in_sfm[image_to_id_colmap[pair[1]]]\n",
    "\n",
    "json_overlaps = []\n",
    "for pair in set(json_pairs):\n",
    "    i1, i2 = pair_to_images(pair)\n",
    "    overlap = i1.point_overlap(i2)\n",
    "    json_overlaps.append(overlap)\n",
    "print(len(json_overlaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541998bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "sfm_pairs = []\n",
    "sfm_overlaps = []\n",
    "n_iter = len(images_in_sfm) * (len(images_in_sfm) - 1) // 2\n",
    "for pair in tqdm(combinations(images_in_sfm.values(), r=2), total=n_iter):\n",
    "    i1, i2 = pair\n",
    "    overlap = i1.point_overlap(i2)\n",
    "    sfm_overlaps.append(overlap)\n",
    "    sfm_pairs.append((i1.name, i2.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1794c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = f'/cvlabdata1/cvlab/datasets_tyszkiew/megadepth/MegaDepth_v1_SfM/{scene_id}/images'\n",
    "load = lambda im: imageio.imread(f'{image_root}/{im}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.arange(0, 600) + 0.5\n",
    "_ = plt.hist(json_overlaps, bins=bins, histtype='step', density=True, label='disk subset')\n",
    "_ = plt.hist(sfm_overlaps, bins=bins, histtype='step', density=True, label='raw megadepth')\n",
    "plt.xlabel('size of intersection of landmarks')\n",
    "plt.ylabel('number of pairs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c372d2-59b1-4924-be88-0ba8f8e3509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, _b = np.histogram(sfm_overlaps, bins=np.arange(0, 600) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_pairs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sfm_overlaps = np.array(sfm_overlaps)\n",
    "pairs_overlap_up_to_5, = np.where((sfm_overlaps > 10) & (sfm_overlaps <= 20))\n",
    "#pairs_overlap_up_to_5, = np.where((sfm_overlaps > 1))\n",
    "np.random.shuffle(pairs_overlap_up_to_5)\n",
    "\n",
    "def show_pairs(pairs: list[tuple[str, str]]):\n",
    "    n = len(pairs)\n",
    "    fig, axes = plt.subplots(n, 2, figsize=(10, n * 5), tight_layout=True)\n",
    "    for i, pair in enumerate(pairs):\n",
    "        a1, a2 = axes[i]\n",
    "        a1.imshow(load(pair[0]))\n",
    "        a2.imshow(load(pair[1]))\n",
    "        a1.axis('off')\n",
    "        a2.axis('off')\n",
    "\n",
    "show_pairs([sfm_pairs[i] for i in pairs_overlap_up_to_5[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a90899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('/cvlabdata1/cvlab/datasets_tyszkiew/megadepth/MegaDepth_v1_SfM/0162/sparse/manhattan/0/split_metadata.h5', 'r') as hdf:\n",
    "    new_names = [name.decode('utf-8') for name in hdf['images'][()]]\n",
    "    new_pairs = []\n",
    "    for pair in hdf['pairs']:\n",
    "        new_pairs.append((new_names[pair[0]], new_names[pair[1]]))\n",
    "    #print(hdf['images'])\n",
    "    #print(hdf['pairs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_overlap = []\n",
    "for pair in new_pairs:\n",
    "    i1, i2 = pair_to_images(pair)\n",
    "    overlap = i1.point_overlap(i2)\n",
    "    new_pairs_overlap.append(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31981bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(new_pairs_overlap, bins=bins, histtype='step', density=False, label='new megadepth')\n",
    "plt.hist(json_overlaps, bins=bins, histtype='step', density=False, label='disk subset')\n",
    "plt.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10233f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_pairs = list(set(new_pairs) - set(json_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c201c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pairs(added_pairs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "all_missing_images = []\n",
    "for root, dirs, files in os.walk('/cvlabdata1/cvlab/datasets_tyszkiew/megadepth/MegaDepth_v1_SfM/'):\n",
    "    if 'missing_images.json' not in files:\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(root, 'missing_images.json'), 'r') as json_file:\n",
    "        missing_file_names = json.load(json_file)\n",
    "\n",
    "    scene_id = root.split('/')[6]\n",
    "    \n",
    "    image_root = f'MegaDepth_v1_SfM/{scene_id}/images'\n",
    "    missing_file_paths = [os.path.join(image_root,  name) for name in missing_file_names]\n",
    "\n",
    "    all_missing_images.extend(missing_file_paths)\n",
    "\n",
    "with open('images_to_unpack.json', 'w') as json_file:\n",
    "    json.dump(all_missing_images, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e30cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_missing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b202f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_missing_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_file_lists import read_cameras_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad94ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_cameras_text('/cvlabdata1/cvlab/datasets_tyszkiew/megadepth/MegaDepth_v1_SfM/0162/sparse/manhattan/0/cameras.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f357fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
